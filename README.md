# Woof or Meow Backend

The back-end for [Woof or Meow](https://github.com/fredchyan/Woof-or-Meow) receives image from the mobile front-end app and uses the IBM Watson Visual Recognition Service to perform analysis on the image. This Node.js server acts like a proxy to Visual Recognition API on Bluemix. Most of the information and code are based on the article ["A real world app with IBM Bluemix, Node, Cordova, and Ionic"](http://www.raymondcamden.com/2015/08/05/a-real-world-app-with-ibm-bluemix-node-cordova-and-ionic/) from Raymond Camden's [Blog](http://www.raymondcamden.com). He also mentioned an alternate way to achieve the same functionality by [Using Authorization Tokens for IBM Watson services](http://www.raymondcamden.com/2015/11/13/using-authorization-tokens-for-ibm-watson-services/).

## Getting Started
1. [Sign up](https://console.ng.bluemix.net) for an IBM Bluemix account 
2. Create a new **Cloud Foundry** App, select **mobile** as the kind of app, and enter a name for the app.
3.  From Services & APIs, add **Visual Recognition**.
4. Download Bluemix and CF Command Line Interface.
5. Download the Starter Code, this is a useful reference because the configuration might change overtime.
6. Clone this repository. This will be the main server app.
7. Use the `manifest.yml` file found in this repository as a reference, modify the `manifest.yml` file from the starter code and overwrite the one in the repository. As of now, the only change needed is the addition of this line: 
    ```
    command: node app.js
    ```
8. Open app.js, fill in the application route and application ID using information available on the Dashboard.
   ```
   	config  	= {
		// change to real application route assigned for your application
		applicationRoute : "APP_ROUTE.mybluemix.net",
		// change to real application ID generated by Bluemix for your application
		applicationId : "APPLICATION_ID"
	};

   ```
9. Fill in the service credential for Visual Recognition, this is needed when testing the server locally. 
    ```
    var visual_recognition = watson.visual_recognition({
      username: 'USERNAME',
      password: 'PASSWORD',
      version: 'v1-beta',
    });
    ```

10. Log in and deploy the server.
    ```
    bluemix api https://api.ng.bluemix.net
    bluemix login -u USERNAME@EMAIL.COM -o USERNAME@EMAIL.COM -s dev
    cf push "APP NAME"
    ```
    
11. If the instance crashes, check the log and fix relevant errors and try pushing again. Once it's running, configure and build the [Woof or Meow](https://github.com/fredchyan/Woof-or-Meow) iOS mobile front-end!

## Notes
Currently (2016/03/08) the IBM Watsonâ„¢ Visual Recognition API is at version 2. Although this code is based on version 1, it will remain accessible until the service exits beta. More information can be found on [here](http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/doc/visual-recognition/releasenotes.shtml).
